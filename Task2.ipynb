{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E_uB2ArSwBY"
      },
      "outputs": [],
      "source": [
        "import tensorflow.compat.v2 as tf #\n",
        "from typing import Union\n",
        "from tensorflow.keras.layers import * \n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras\n",
        "import numpy\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "tf.enable_v2_behavior()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTmY6TPBS61j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b0cd708-440a-4472-901b-921e9b8c1983"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xaePJB_BS8Tb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir(r'/content/drive/My Drive/mhist_dataset/images/images')  # Change the directory to the project folder in your drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1olnIkbYTOKL"
      },
      "source": [
        "#Import dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DPN8Jz2-Uy71"
      },
      "outputs": [],
      "source": [
        "image_table=pd.read_csv('/content/drive/My Drive/mhist_dataset/annotations.csv') #make sure this is pointing to the csv location"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pirvU9F7VS8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d987aa57-6b3c-4814-b2fb-93fe7e55490d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2175, 4)\n"
          ]
        }
      ],
      "source": [
        "train_set=image_table.loc[image_table['Partition'] == 'train']\n",
        "print(train_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2mCJFLpV255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4a1a7ff-22e8-4e3e-ada6-a739285e9781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(977, 4)\n"
          ]
        }
      ],
      "source": [
        "test_set=image_table.loc[image_table['Partition'] == 'test']\n",
        "print(test_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6wzn3mh0V5Ks"
      },
      "outputs": [],
      "source": [
        "image_dir = '/content/drive/My Drive/mhist_dataset/images/images'  #you should change to your directory "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cu1qiZ9yV_PQ"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
        "shear_range=0.1,\n",
        "rotation_range=15,\n",
        "horizontal_flip=True,\n",
        "vertical_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQRMDQNAWAN4",
        "outputId": "56edff76-e184-4c2e-e86e-136bfd97e405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2175 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator=train_datagen.flow_from_dataframe(\n",
        "dataframe=train_set,\n",
        "directory=image_dir,\n",
        "x_col=\"Image Name\",\n",
        "y_col=\"Majority Vote Label\",\n",
        "batch_size=32,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "interpolation='bilinear',\n",
        "class_mode=\"categorical\",\n",
        "target_size=(224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRksftvSWKXj",
        "outputId": "e3d08466-59f1-4b1a-d904-a272036dd8d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 977 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=test_set,\n",
        "directory=image_dir,\n",
        "x_col=\"Image Name\",\n",
        "y_col=\"Majority Vote Label\",\n",
        "seed=42,\n",
        "class_mode='categorical',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=32,\n",
        "shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJu0n1YaWOso"
      },
      "source": [
        "#Create models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0unEE9iyWSiw"
      },
      "outputs": [],
      "source": [
        "#download resnet\n",
        "resnet=tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa3I7r-8WXXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ad4bc2-c5aa-41f5-f40f-12fbc23ca466"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191\n"
          ]
        }
      ],
      "source": [
        "#making select layers trainable\n",
        "count=0\n",
        "for layers in resnet.layers:\n",
        "  count+=1\n",
        "  if count== 191:\n",
        "    continue\n",
        "  if(layers.name[0:5]== 'conv5' or layers.name[0:5]== 'post_'):\n",
        "    continue\n",
        "  else:\n",
        "    layers.trainable=False\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKR22QXNWd8U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "444d3c86-3e84-48c6-d596-8ef0521c02cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False input 1\n",
            "False conv1 2\n",
            "False conv1 3\n",
            "False pool1 4\n",
            "False pool1 5\n",
            "False conv2 6\n",
            "False conv2 7\n",
            "False conv2 8\n",
            "False conv2 9\n",
            "False conv2 10\n",
            "False conv2 11\n",
            "False conv2 12\n",
            "False conv2 13\n",
            "False conv2 14\n",
            "False conv2 15\n",
            "False conv2 16\n",
            "False conv2 17\n",
            "False conv2 18\n",
            "False conv2 19\n",
            "False conv2 20\n",
            "False conv2 21\n",
            "False conv2 22\n",
            "False conv2 23\n",
            "False conv2 24\n",
            "False conv2 25\n",
            "False conv2 26\n",
            "False conv2 27\n",
            "False conv2 28\n",
            "False conv2 29\n",
            "False conv2 30\n",
            "False conv2 31\n",
            "False conv2 32\n",
            "False conv2 33\n",
            "False conv2 34\n",
            "False conv2 35\n",
            "False conv2 36\n",
            "False conv2 37\n",
            "False max_p 38\n",
            "False conv2 39\n",
            "False conv2 40\n",
            "False conv3 41\n",
            "False conv3 42\n",
            "False conv3 43\n",
            "False conv3 44\n",
            "False conv3 45\n",
            "False conv3 46\n",
            "False conv3 47\n",
            "False conv3 48\n",
            "False conv3 49\n",
            "False conv3 50\n",
            "False conv3 51\n",
            "False conv3 52\n",
            "False conv3 53\n",
            "False conv3 54\n",
            "False conv3 55\n",
            "False conv3 56\n",
            "False conv3 57\n",
            "False conv3 58\n",
            "False conv3 59\n",
            "False conv3 60\n",
            "False conv3 61\n",
            "False conv3 62\n",
            "False conv3 63\n",
            "False conv3 64\n",
            "False conv3 65\n",
            "False conv3 66\n",
            "False conv3 67\n",
            "False conv3 68\n",
            "False conv3 69\n",
            "False conv3 70\n",
            "False conv3 71\n",
            "False conv3 72\n",
            "False conv3 73\n",
            "False conv3 74\n",
            "False conv3 75\n",
            "False conv3 76\n",
            "False conv3 77\n",
            "False conv3 78\n",
            "False conv3 79\n",
            "False conv3 80\n",
            "False conv3 81\n",
            "False conv3 82\n",
            "False conv3 83\n",
            "False max_p 84\n",
            "False conv3 85\n",
            "False conv3 86\n",
            "False conv4 87\n",
            "False conv4 88\n",
            "False conv4 89\n",
            "False conv4 90\n",
            "False conv4 91\n",
            "False conv4 92\n",
            "False conv4 93\n",
            "False conv4 94\n",
            "False conv4 95\n",
            "False conv4 96\n",
            "False conv4 97\n",
            "False conv4 98\n",
            "False conv4 99\n",
            "False conv4 100\n",
            "False conv4 101\n",
            "False conv4 102\n",
            "False conv4 103\n",
            "False conv4 104\n",
            "False conv4 105\n",
            "False conv4 106\n",
            "False conv4 107\n",
            "False conv4 108\n",
            "False conv4 109\n",
            "False conv4 110\n",
            "False conv4 111\n",
            "False conv4 112\n",
            "False conv4 113\n",
            "False conv4 114\n",
            "False conv4 115\n",
            "False conv4 116\n",
            "False conv4 117\n",
            "False conv4 118\n",
            "False conv4 119\n",
            "False conv4 120\n",
            "False conv4 121\n",
            "False conv4 122\n",
            "False conv4 123\n",
            "False conv4 124\n",
            "False conv4 125\n",
            "False conv4 126\n",
            "False conv4 127\n",
            "False conv4 128\n",
            "False conv4 129\n",
            "False conv4 130\n",
            "False conv4 131\n",
            "False conv4 132\n",
            "False conv4 133\n",
            "False conv4 134\n",
            "False conv4 135\n",
            "False conv4 136\n",
            "False conv4 137\n",
            "False conv4 138\n",
            "False conv4 139\n",
            "False conv4 140\n",
            "False conv4 141\n",
            "False conv4 142\n",
            "False conv4 143\n",
            "False conv4 144\n",
            "False conv4 145\n",
            "False conv4 146\n",
            "False conv4 147\n",
            "False conv4 148\n",
            "False conv4 149\n",
            "False conv4 150\n",
            "False conv4 151\n",
            "False max_p 152\n",
            "False conv4 153\n",
            "False conv4 154\n",
            "True conv5 155\n",
            "True conv5 156\n",
            "True conv5 157\n",
            "True conv5 158\n",
            "True conv5 159\n",
            "True conv5 160\n",
            "True conv5 161\n",
            "True conv5 162\n",
            "True conv5 163\n",
            "True conv5 164\n",
            "True conv5 165\n",
            "True conv5 166\n",
            "True conv5 167\n",
            "True conv5 168\n",
            "True conv5 169\n",
            "True conv5 170\n",
            "True conv5 171\n",
            "True conv5 172\n",
            "True conv5 173\n",
            "True conv5 174\n",
            "True conv5 175\n",
            "True conv5 176\n",
            "True conv5 177\n",
            "True conv5 178\n",
            "True conv5 179\n",
            "True conv5 180\n",
            "True conv5 181\n",
            "True conv5 182\n",
            "True conv5 183\n",
            "True conv5 184\n",
            "True conv5 185\n",
            "True conv5 186\n",
            "True conv5 187\n",
            "True conv5 188\n",
            "True post_ 189\n",
            "True post_ 190\n",
            "True avg_p 191\n"
          ]
        }
      ],
      "source": [
        "#checking the layers\n",
        "count=0\n",
        "for layers in resnet.layers:\n",
        "  count+=1\n",
        "  print(layers.trainable, layers.name[0:5], count)\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oEXB64TWhC4"
      },
      "outputs": [],
      "source": [
        "#final teacher model\n",
        "teacher_res=tf.keras.Sequential([resnet,Dense(units=2, activation='linear')])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XMeX8WXhKuws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjrrtSAxSIwb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1032aef2-a252-42c7-8afe-10729a9c6fc1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,568,898\n",
            "Trainable params: 14,974,978\n",
            "Non-trainable params: 8,593,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "teacher_res.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwCg9CsMWjFB"
      },
      "outputs": [],
      "source": [
        "#download mobilenet\n",
        "mobilenet=tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    alpha=1.0,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling='max',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNIFhyXYWmsa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "948017f4-90fe-452a-ac45-5da1a86558d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155\n"
          ]
        }
      ],
      "source": [
        "#making select layers trainable\n",
        "count=0\n",
        "for layers in mobilenet.layers:\n",
        "  count+=1\n",
        "  if count> 151:\n",
        "    continue\n",
        "  if(layers.name[0:8]== 'block_16' ):\n",
        "    continue\n",
        "  else:\n",
        "    layers.trainable=False\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Skx5OXukWo4Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "727d0d7c-9ba4-482d-add2-72969015405f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False input_5 0\n",
            "False Conv1 1\n",
            "False bn_Conv1 2\n",
            "False Conv1_re 3\n",
            "False expanded 4\n",
            "False expanded 5\n",
            "False expanded 6\n",
            "False expanded 7\n",
            "False expanded 8\n",
            "False block_1_ 9\n",
            "False block_1_ 10\n",
            "False block_1_ 11\n",
            "False block_1_ 12\n",
            "False block_1_ 13\n",
            "False block_1_ 14\n",
            "False block_1_ 15\n",
            "False block_1_ 16\n",
            "False block_1_ 17\n",
            "False block_2_ 18\n",
            "False block_2_ 19\n",
            "False block_2_ 20\n",
            "False block_2_ 21\n",
            "False block_2_ 22\n",
            "False block_2_ 23\n",
            "False block_2_ 24\n",
            "False block_2_ 25\n",
            "False block_2_ 26\n",
            "False block_3_ 27\n",
            "False block_3_ 28\n",
            "False block_3_ 29\n",
            "False block_3_ 30\n",
            "False block_3_ 31\n",
            "False block_3_ 32\n",
            "False block_3_ 33\n",
            "False block_3_ 34\n",
            "False block_3_ 35\n",
            "False block_4_ 36\n",
            "False block_4_ 37\n",
            "False block_4_ 38\n",
            "False block_4_ 39\n",
            "False block_4_ 40\n",
            "False block_4_ 41\n",
            "False block_4_ 42\n",
            "False block_4_ 43\n",
            "False block_4_ 44\n",
            "False block_5_ 45\n",
            "False block_5_ 46\n",
            "False block_5_ 47\n",
            "False block_5_ 48\n",
            "False block_5_ 49\n",
            "False block_5_ 50\n",
            "False block_5_ 51\n",
            "False block_5_ 52\n",
            "False block_5_ 53\n",
            "False block_6_ 54\n",
            "False block_6_ 55\n",
            "False block_6_ 56\n",
            "False block_6_ 57\n",
            "False block_6_ 58\n",
            "False block_6_ 59\n",
            "False block_6_ 60\n",
            "False block_6_ 61\n",
            "False block_6_ 62\n",
            "False block_7_ 63\n",
            "False block_7_ 64\n",
            "False block_7_ 65\n",
            "False block_7_ 66\n",
            "False block_7_ 67\n",
            "False block_7_ 68\n",
            "False block_7_ 69\n",
            "False block_7_ 70\n",
            "False block_7_ 71\n",
            "False block_8_ 72\n",
            "False block_8_ 73\n",
            "False block_8_ 74\n",
            "False block_8_ 75\n",
            "False block_8_ 76\n",
            "False block_8_ 77\n",
            "False block_8_ 78\n",
            "False block_8_ 79\n",
            "False block_8_ 80\n",
            "False block_9_ 81\n",
            "False block_9_ 82\n",
            "False block_9_ 83\n",
            "False block_9_ 84\n",
            "False block_9_ 85\n",
            "False block_9_ 86\n",
            "False block_9_ 87\n",
            "False block_9_ 88\n",
            "False block_9_ 89\n",
            "False block_10 90\n",
            "False block_10 91\n",
            "False block_10 92\n",
            "False block_10 93\n",
            "False block_10 94\n",
            "False block_10 95\n",
            "False block_10 96\n",
            "False block_10 97\n",
            "False block_11 98\n",
            "False block_11 99\n",
            "False block_11 100\n",
            "False block_11 101\n",
            "False block_11 102\n",
            "False block_11 103\n",
            "False block_11 104\n",
            "False block_11 105\n",
            "False block_11 106\n",
            "False block_12 107\n",
            "False block_12 108\n",
            "False block_12 109\n",
            "False block_12 110\n",
            "False block_12 111\n",
            "False block_12 112\n",
            "False block_12 113\n",
            "False block_12 114\n",
            "False block_12 115\n",
            "False block_13 116\n",
            "False block_13 117\n",
            "False block_13 118\n",
            "False block_13 119\n",
            "False block_13 120\n",
            "False block_13 121\n",
            "False block_13 122\n",
            "False block_13 123\n",
            "False block_13 124\n",
            "False block_14 125\n",
            "False block_14 126\n",
            "False block_14 127\n",
            "False block_14 128\n",
            "False block_14 129\n",
            "False block_14 130\n",
            "False block_14 131\n",
            "False block_14 132\n",
            "False block_14 133\n",
            "False block_15 134\n",
            "False block_15 135\n",
            "False block_15 136\n",
            "False block_15 137\n",
            "False block_15 138\n",
            "False block_15 139\n",
            "False block_15 140\n",
            "False block_15 141\n",
            "False block_15 142\n",
            "True block_16 143\n",
            "True block_16 144\n",
            "True block_16 145\n",
            "True block_16 146\n",
            "True block_16 147\n",
            "True block_16 148\n",
            "True block_16 149\n",
            "True block_16 150\n",
            "True Conv_1 151\n",
            "True Conv_1_b 152\n",
            "True out_relu 153\n",
            "True global_m 154\n"
          ]
        }
      ],
      "source": [
        "#checking layers\n",
        "count=0\n",
        "for layers in mobilenet.layers:\n",
        "  print(layers.trainable, layers.name[0:8], count)\n",
        "  count+=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gpFFJPosWt0Q"
      },
      "outputs": [],
      "source": [
        "#final student model\n",
        "student_mobile=tf.keras.Sequential([mobilenet,Dense(units=2, activation='linear')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yxs2mVwhVuo4"
      },
      "outputs": [],
      "source": [
        "#download mobile net again\n",
        "mobilenet2=tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    alpha=1.0,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling='max',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74X6FkSIV0Zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a914f8b-6a02-42b1-9bb1-45c59fb2d7db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155\n"
          ]
        }
      ],
      "source": [
        "#making salect layers trainable\n",
        "count=0\n",
        "for layers in mobilenet2.layers:\n",
        "  count+=1\n",
        "  if count> 151:\n",
        "    continue\n",
        "  if(layers.name[0:8]== 'block_16' ):\n",
        "    continue\n",
        "  else:\n",
        "    layers.trainable=False\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uaLRS_7gWwOR"
      },
      "outputs": [],
      "source": [
        "#final student without kd\n",
        "mobilenet_no_kd=tf.keras.Sequential([mobilenet2,Dense(units=2, activation='linear')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2-2UJFlq8_H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ec1de8-c44b-40b3-d9d1-b6217ed20600"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 2)                 2562      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,260,546\n",
            "Trainable params: 888,642\n",
            "Non-trainable params: 1,371,904\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "mobilenet_no_kd.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XlLYcw9aX3RF"
      },
      "source": [
        "#Training functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMIFSSfAX7gC"
      },
      "outputs": [],
      "source": [
        "def compute_teacher_loss_res(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation teacher loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = teacher_res(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for subclasses.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  \n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(axis=-1,name='categorical_crossentropy')\n",
        "  cross_entropy_loss_value = loss(labels,tf.nn.softmax(subclass_logits, axis=-1))\n",
        "\n",
        "\n",
        "  return cross_entropy_loss_value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmWL7aA32P3q"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters for distillation (need to be tuned).\n",
        "ALPHA = 0.9 # task balance between cross-entropy and distillation loss\n",
        "DISTILLATION_TEMPERATURE = 8. #temperature hyperparameter\n",
        "\n",
        "def distillation_loss(teacher_logits: tf.Tensor, student_logits: tf.Tensor,\n",
        "                      temperature: Union[float, tf.Tensor]):\n",
        "  \"\"\"Compute distillation loss.\n",
        "\n",
        "  This function computes cross entropy between softened logits and softened\n",
        "  targets. The resulting loss is scaled by the squared temperature so that\n",
        "  the gradient magnitude remains approximately constant as the temperature is\n",
        "  changed. For reference, see Hinton et al., 2014, \"Distilling the knowledge in\n",
        "  a neural network.\"\n",
        "\n",
        "  Args:\n",
        "    teacher_logits: A Tensor of logits provided by the teacher.\n",
        "    student_logits: A Tensor of logits provided by the student, of the same\n",
        "      shape as `teacher_logits`.\n",
        "    temperature: Temperature to use for distillation.\n",
        "\n",
        "  Returns:\n",
        "    A scalar Tensor containing the distillation loss.\n",
        "  \"\"\"\n",
        " # your code start from here for step 3\n",
        "  soft_targets = tf.nn.softmax(teacher_logits/temperature)\n",
        "\n",
        "  return tf.reduce_mean(\n",
        "      tf.nn.softmax_cross_entropy_with_logits(\n",
        "          soft_targets, student_logits / temperature)) * temperature ** 2\n",
        "\n",
        "def compute_student_loss(images, labels, ALPHA=0.8, DISTILLATION_TEMPERATURE=8. ):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_subclass_logits = student_mobile(images, training=True)\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "\n",
        "  teacher_subclass_logits = teacher_res(images, training=False)\n",
        "  distillation_loss_value =distillation_loss(teacher_subclass_logits,student_subclass_logits, DISTILLATION_TEMPERATURE )\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  # your code start from here for step 3\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(axis=-1,name='categorical_crossentropy')\n",
        "  cross_entropy_loss_value = loss(labels,tf.nn.softmax(student_subclass_logits, axis=-1))\n",
        "\n",
        "  return (ALPHA*  distillation_loss_value + (1-ALPHA)* cross_entropy_loss_value) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLJudWf1YjZf"
      },
      "outputs": [],
      "source": [
        "def compute_num_correct(model, images, labels):\n",
        "  \"\"\"Compute number of correctly classified images in a batch.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Number of correctly classified images.\n",
        "  \"\"\"\n",
        "  class_logits = model(images, training=False)\n",
        "  return tf.math.reduce_sum(tf.cast(tf.math.equal(tf.argmax(class_logits, -1), tf.argmax(labels, -1)),tf.float32)), tf.argmax(class_logits, -1), tf.argmax(labels, -1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zJDdZYJEZKY9"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_teacher(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  for epoch in range(1, 10 + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        \n",
        "        # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "    \n",
        "  #fine tuning\n",
        "  print('fine tuning')\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "  m=teacher_res.get_layer('resnet50v2')\n",
        "  count=0\n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    if count== 152:\n",
        "      layers.trainable=True\n",
        "    if(layers.name[0:5]== 'conv4'):\n",
        "      layers.trainable=True\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  count=0  \n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    print(layers.trainable, layers.name[0:5], count)\n",
        "\n",
        "  for epoch in range(1, 25 + 1):\n",
        "  # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "        # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    \n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_Bahk4_ZZ9w"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_kd(model, compute_loss_fn, ALPHA=0.8, DISTILLATION_TEMPERATURE=8.):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "  for epoch in range(1, 10 + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels, ALPHA, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "  \n",
        "  #fine tuning\n",
        "  print('fine tuning')\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  m=student_mobile.get_layer('mobilenetv2_1.00_224')\n",
        "\n",
        "  for layers in m.layers:\n",
        "    if(layers.name[0:8]== 'block_15'):\n",
        "      layers.trainable=True\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  count=0  \n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    print(layers.trainable, layers.name[0:8], count)\n",
        "\n",
        "  for epoch in range(1, 25 + 1):\n",
        "  # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "        # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels, ALPHA, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    \n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpjnASIJbt_R"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_no_kd(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "  for epoch in range(1, 10 + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "          # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "    \n",
        "  #fine tuning\n",
        "  print('fine tuning')\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  m=mobilenet_no_kd.get_layer('mobilenetv2_1.00_224')\n",
        "\n",
        "  for layers in m.layers:\n",
        "    if(layers.name[0:8]== 'block_15'):\n",
        "      layers.trainable=True\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  count=0  \n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    print(layers.trainable, layers.name[0:8], count)\n",
        "\n",
        "  for epoch in range(1, 25 + 1):\n",
        "  # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "        # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    \n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkvvtVz2ZaIT"
      },
      "outputs": [],
      "source": [
        "def compute_plain_cross_entropy_loss_mobile(images, labels):\n",
        "  \"\"\"Compute plain loss for given images and labels.\n",
        "\n",
        "  For fair comparison and convenience, this function also performs a\n",
        "  LogSumExp over subclasses, but does not perform subclass distillation.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  # your code start from here for step 7\n",
        "\n",
        "  student_subclass_logits = mobilenet_no_kd(images, training=True)\n",
        "  #print(student_subclass_logits[0])\n",
        "  #print(labels[0])\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(axis=-1,name='categorical_crossentropy')\n",
        "  cross_entropy_loss = loss(labels,tf.nn.softmax(student_subclass_logits, axis=-1))\n",
        "  #print(cross_entropy_loss)\n",
        "  return cross_entropy_loss\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZgnutu0n3Im"
      },
      "source": [
        "#Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sryCp_-SLw0O",
        "outputId": "3386df2b-5913-48f4-bae0-ada3513bbc42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 81.78%\n",
            "Epoch 2: Class_accuracy: 76.66%\n",
            "Epoch 3: Class_accuracy: 79.43%\n",
            "Epoch 4: Class_accuracy: 77.28%\n",
            "Epoch 5: Class_accuracy: 81.88%\n",
            "Epoch 6: Class_accuracy: 81.68%\n",
            "Epoch 7: Class_accuracy: 81.37%\n",
            "Epoch 8: Class_accuracy: 81.88%\n",
            "Epoch 9: Class_accuracy: 81.78%\n",
            "Epoch 10: Class_accuracy: 82.70%\n",
            "fine tuning\n",
            "False input 1\n",
            "False conv1 2\n",
            "False conv1 3\n",
            "False pool1 4\n",
            "False pool1 5\n",
            "False conv2 6\n",
            "False conv2 7\n",
            "False conv2 8\n",
            "False conv2 9\n",
            "False conv2 10\n",
            "False conv2 11\n",
            "False conv2 12\n",
            "False conv2 13\n",
            "False conv2 14\n",
            "False conv2 15\n",
            "False conv2 16\n",
            "False conv2 17\n",
            "False conv2 18\n",
            "False conv2 19\n",
            "False conv2 20\n",
            "False conv2 21\n",
            "False conv2 22\n",
            "False conv2 23\n",
            "False conv2 24\n",
            "False conv2 25\n",
            "False conv2 26\n",
            "False conv2 27\n",
            "False conv2 28\n",
            "False conv2 29\n",
            "False conv2 30\n",
            "False conv2 31\n",
            "False conv2 32\n",
            "False conv2 33\n",
            "False conv2 34\n",
            "False conv2 35\n",
            "False conv2 36\n",
            "False conv2 37\n",
            "False max_p 38\n",
            "False conv2 39\n",
            "False conv2 40\n",
            "False conv3 41\n",
            "False conv3 42\n",
            "False conv3 43\n",
            "False conv3 44\n",
            "False conv3 45\n",
            "False conv3 46\n",
            "False conv3 47\n",
            "False conv3 48\n",
            "False conv3 49\n",
            "False conv3 50\n",
            "False conv3 51\n",
            "False conv3 52\n",
            "False conv3 53\n",
            "False conv3 54\n",
            "False conv3 55\n",
            "False conv3 56\n",
            "False conv3 57\n",
            "False conv3 58\n",
            "False conv3 59\n",
            "False conv3 60\n",
            "False conv3 61\n",
            "False conv3 62\n",
            "False conv3 63\n",
            "False conv3 64\n",
            "False conv3 65\n",
            "False conv3 66\n",
            "False conv3 67\n",
            "False conv3 68\n",
            "False conv3 69\n",
            "False conv3 70\n",
            "False conv3 71\n",
            "False conv3 72\n",
            "False conv3 73\n",
            "False conv3 74\n",
            "False conv3 75\n",
            "False conv3 76\n",
            "False conv3 77\n",
            "False conv3 78\n",
            "False conv3 79\n",
            "False conv3 80\n",
            "False conv3 81\n",
            "False conv3 82\n",
            "False conv3 83\n",
            "False max_p 84\n",
            "False conv3 85\n",
            "False conv3 86\n",
            "True conv4 87\n",
            "True conv4 88\n",
            "True conv4 89\n",
            "True conv4 90\n",
            "True conv4 91\n",
            "True conv4 92\n",
            "True conv4 93\n",
            "True conv4 94\n",
            "True conv4 95\n",
            "True conv4 96\n",
            "True conv4 97\n",
            "True conv4 98\n",
            "True conv4 99\n",
            "True conv4 100\n",
            "True conv4 101\n",
            "True conv4 102\n",
            "True conv4 103\n",
            "True conv4 104\n",
            "True conv4 105\n",
            "True conv4 106\n",
            "True conv4 107\n",
            "True conv4 108\n",
            "True conv4 109\n",
            "True conv4 110\n",
            "True conv4 111\n",
            "True conv4 112\n",
            "True conv4 113\n",
            "True conv4 114\n",
            "True conv4 115\n",
            "True conv4 116\n",
            "True conv4 117\n",
            "True conv4 118\n",
            "True conv4 119\n",
            "True conv4 120\n",
            "True conv4 121\n",
            "True conv4 122\n",
            "True conv4 123\n",
            "True conv4 124\n",
            "True conv4 125\n",
            "True conv4 126\n",
            "True conv4 127\n",
            "True conv4 128\n",
            "True conv4 129\n",
            "True conv4 130\n",
            "True conv4 131\n",
            "True conv4 132\n",
            "True conv4 133\n",
            "True conv4 134\n",
            "True conv4 135\n",
            "True conv4 136\n",
            "True conv4 137\n",
            "True conv4 138\n",
            "True conv4 139\n",
            "True conv4 140\n",
            "True conv4 141\n",
            "True conv4 142\n",
            "True conv4 143\n",
            "True conv4 144\n",
            "True conv4 145\n",
            "True conv4 146\n",
            "True conv4 147\n",
            "True conv4 148\n",
            "True conv4 149\n",
            "True conv4 150\n",
            "True conv4 151\n",
            "True max_p 152\n",
            "True conv4 153\n",
            "True conv4 154\n",
            "True conv5 155\n",
            "True conv5 156\n",
            "True conv5 157\n",
            "True conv5 158\n",
            "True conv5 159\n",
            "True conv5 160\n",
            "True conv5 161\n",
            "True conv5 162\n",
            "True conv5 163\n",
            "True conv5 164\n",
            "True conv5 165\n",
            "True conv5 166\n",
            "True conv5 167\n",
            "True conv5 168\n",
            "True conv5 169\n",
            "True conv5 170\n",
            "True conv5 171\n",
            "True conv5 172\n",
            "True conv5 173\n",
            "True conv5 174\n",
            "True conv5 175\n",
            "True conv5 176\n",
            "True conv5 177\n",
            "True conv5 178\n",
            "True conv5 179\n",
            "True conv5 180\n",
            "True conv5 181\n",
            "True conv5 182\n",
            "True conv5 183\n",
            "True conv5 184\n",
            "True conv5 185\n",
            "True conv5 186\n",
            "True conv5 187\n",
            "True conv5 188\n",
            "True post_ 189\n",
            "True post_ 190\n",
            "True avg_p 191\n",
            "Epoch 1: Class_accuracy: 83.11%\n",
            "Epoch 2: Class_accuracy: 83.62%\n",
            "Epoch 3: Class_accuracy: 83.73%\n",
            "Epoch 4: Class_accuracy: 83.11%\n",
            "Epoch 5: Class_accuracy: 84.03%\n",
            "Epoch 6: Class_accuracy: 83.01%\n",
            "Epoch 7: Class_accuracy: 84.14%\n",
            "Epoch 8: Class_accuracy: 84.14%\n",
            "Epoch 9: Class_accuracy: 84.34%\n",
            "Epoch 10: Class_accuracy: 84.14%\n",
            "Epoch 11: Class_accuracy: 83.42%\n",
            "Epoch 12: Class_accuracy: 83.73%\n",
            "Epoch 13: Class_accuracy: 83.01%\n",
            "Epoch 14: Class_accuracy: 83.42%\n",
            "Epoch 15: Class_accuracy: 83.52%\n",
            "Epoch 16: Class_accuracy: 83.42%\n",
            "Epoch 17: Class_accuracy: 83.32%\n",
            "Epoch 18: Class_accuracy: 83.93%\n",
            "Epoch 19: Class_accuracy: 83.21%\n",
            "Epoch 20: Class_accuracy: 83.62%\n",
            "Epoch 21: Class_accuracy: 83.52%\n",
            "Epoch 22: Class_accuracy: 83.42%\n",
            "Epoch 23: Class_accuracy: 84.34%\n",
            "Epoch 24: Class_accuracy: 84.14%\n",
            "Epoch 25: Class_accuracy: 84.54%\n"
          ]
        }
      ],
      "source": [
        "#teacher training\n",
        "train_and_evaluate_teacher(teacher_res,compute_teacher_loss_res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "02vkpVAUkq9f",
        "outputId": "159e1c48-8faf-473c-886b-6979a1f68abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "#saving the teacher model\n",
        "teacher_res.save('teacher_res_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXiOVQ7qo11f",
        "outputId": "72526799-03ff-4070-b367-aafaa688d84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#loading the teacher model\n",
        "teacher_res=keras.models.load_model('/content/drive/MyDrive/mhist_dataset/teacher_res_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MGXi227sgT3",
        "outputId": "7d38f126-e3f4-4fb1-c9a2-44e97d6e0405"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 63.25%\n",
            "Epoch 2: Class_accuracy: 63.46%\n",
            "Epoch 3: Class_accuracy: 64.79%\n",
            "Epoch 4: Class_accuracy: 63.66%\n",
            "Epoch 5: Class_accuracy: 72.88%\n",
            "Epoch 6: Class_accuracy: 72.47%\n",
            "Epoch 7: Class_accuracy: 67.35%\n",
            "Epoch 8: Class_accuracy: 73.59%\n",
            "Epoch 9: Class_accuracy: 74.10%\n",
            "Epoch 10: Class_accuracy: 76.15%\n",
            "fine tuning\n",
            "False input_6 1\n",
            "False Conv1 2\n",
            "False bn_Conv1 3\n",
            "False Conv1_re 4\n",
            "False expanded 5\n",
            "False expanded 6\n",
            "False expanded 7\n",
            "False expanded 8\n",
            "False expanded 9\n",
            "False block_1_ 10\n",
            "False block_1_ 11\n",
            "False block_1_ 12\n",
            "False block_1_ 13\n",
            "False block_1_ 14\n",
            "False block_1_ 15\n",
            "False block_1_ 16\n",
            "False block_1_ 17\n",
            "False block_1_ 18\n",
            "False block_2_ 19\n",
            "False block_2_ 20\n",
            "False block_2_ 21\n",
            "False block_2_ 22\n",
            "False block_2_ 23\n",
            "False block_2_ 24\n",
            "False block_2_ 25\n",
            "False block_2_ 26\n",
            "False block_2_ 27\n",
            "False block_3_ 28\n",
            "False block_3_ 29\n",
            "False block_3_ 30\n",
            "False block_3_ 31\n",
            "False block_3_ 32\n",
            "False block_3_ 33\n",
            "False block_3_ 34\n",
            "False block_3_ 35\n",
            "False block_3_ 36\n",
            "False block_4_ 37\n",
            "False block_4_ 38\n",
            "False block_4_ 39\n",
            "False block_4_ 40\n",
            "False block_4_ 41\n",
            "False block_4_ 42\n",
            "False block_4_ 43\n",
            "False block_4_ 44\n",
            "False block_4_ 45\n",
            "False block_5_ 46\n",
            "False block_5_ 47\n",
            "False block_5_ 48\n",
            "False block_5_ 49\n",
            "False block_5_ 50\n",
            "False block_5_ 51\n",
            "False block_5_ 52\n",
            "False block_5_ 53\n",
            "False block_5_ 54\n",
            "False block_6_ 55\n",
            "False block_6_ 56\n",
            "False block_6_ 57\n",
            "False block_6_ 58\n",
            "False block_6_ 59\n",
            "False block_6_ 60\n",
            "False block_6_ 61\n",
            "False block_6_ 62\n",
            "False block_6_ 63\n",
            "False block_7_ 64\n",
            "False block_7_ 65\n",
            "False block_7_ 66\n",
            "False block_7_ 67\n",
            "False block_7_ 68\n",
            "False block_7_ 69\n",
            "False block_7_ 70\n",
            "False block_7_ 71\n",
            "False block_7_ 72\n",
            "False block_8_ 73\n",
            "False block_8_ 74\n",
            "False block_8_ 75\n",
            "False block_8_ 76\n",
            "False block_8_ 77\n",
            "False block_8_ 78\n",
            "False block_8_ 79\n",
            "False block_8_ 80\n",
            "False block_8_ 81\n",
            "False block_9_ 82\n",
            "False block_9_ 83\n",
            "False block_9_ 84\n",
            "False block_9_ 85\n",
            "False block_9_ 86\n",
            "False block_9_ 87\n",
            "False block_9_ 88\n",
            "False block_9_ 89\n",
            "False block_9_ 90\n",
            "False block_10 91\n",
            "False block_10 92\n",
            "False block_10 93\n",
            "False block_10 94\n",
            "False block_10 95\n",
            "False block_10 96\n",
            "False block_10 97\n",
            "False block_10 98\n",
            "False block_11 99\n",
            "False block_11 100\n",
            "False block_11 101\n",
            "False block_11 102\n",
            "False block_11 103\n",
            "False block_11 104\n",
            "False block_11 105\n",
            "False block_11 106\n",
            "False block_11 107\n",
            "False block_12 108\n",
            "False block_12 109\n",
            "False block_12 110\n",
            "False block_12 111\n",
            "False block_12 112\n",
            "False block_12 113\n",
            "False block_12 114\n",
            "False block_12 115\n",
            "False block_12 116\n",
            "False block_13 117\n",
            "False block_13 118\n",
            "False block_13 119\n",
            "False block_13 120\n",
            "False block_13 121\n",
            "False block_13 122\n",
            "False block_13 123\n",
            "False block_13 124\n",
            "False block_13 125\n",
            "False block_14 126\n",
            "False block_14 127\n",
            "False block_14 128\n",
            "False block_14 129\n",
            "False block_14 130\n",
            "False block_14 131\n",
            "False block_14 132\n",
            "False block_14 133\n",
            "False block_14 134\n",
            "True block_15 135\n",
            "True block_15 136\n",
            "True block_15 137\n",
            "True block_15 138\n",
            "True block_15 139\n",
            "True block_15 140\n",
            "True block_15 141\n",
            "True block_15 142\n",
            "True block_15 143\n",
            "True block_16 144\n",
            "True block_16 145\n",
            "True block_16 146\n",
            "True block_16 147\n",
            "True block_16 148\n",
            "True block_16 149\n",
            "True block_16 150\n",
            "True block_16 151\n",
            "True Conv_1 152\n",
            "True Conv_1_b 153\n",
            "True out_relu 154\n",
            "True global_m 155\n",
            "Epoch 1: Class_accuracy: 65.71%\n",
            "Epoch 2: Class_accuracy: 66.94%\n",
            "Epoch 3: Class_accuracy: 64.79%\n",
            "Epoch 4: Class_accuracy: 64.99%\n",
            "Epoch 5: Class_accuracy: 64.89%\n",
            "Epoch 6: Class_accuracy: 64.89%\n",
            "Epoch 7: Class_accuracy: 68.07%\n",
            "Epoch 8: Class_accuracy: 67.45%\n",
            "Epoch 9: Class_accuracy: 67.04%\n",
            "Epoch 10: Class_accuracy: 64.89%\n",
            "Epoch 11: Class_accuracy: 69.81%\n",
            "Epoch 12: Class_accuracy: 72.98%\n",
            "Epoch 13: Class_accuracy: 73.90%\n",
            "Epoch 14: Class_accuracy: 73.18%\n",
            "Epoch 15: Class_accuracy: 75.95%\n",
            "Epoch 16: Class_accuracy: 77.69%\n",
            "Epoch 17: Class_accuracy: 73.59%\n",
            "Epoch 18: Class_accuracy: 74.92%\n",
            "Epoch 19: Class_accuracy: 77.89%\n",
            "Epoch 20: Class_accuracy: 78.10%\n",
            "Epoch 21: Class_accuracy: 74.51%\n",
            "Epoch 22: Class_accuracy: 72.88%\n",
            "Epoch 23: Class_accuracy: 72.16%\n",
            "Epoch 24: Class_accuracy: 68.17%\n",
            "Epoch 25: Class_accuracy: 69.29%\n"
          ]
        }
      ],
      "source": [
        "# training student without KD\n",
        "train_and_evaluate_no_kd(mobilenet_no_kd, compute_plain_cross_entropy_loss_mobile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcYQ9ULLSxfX",
        "outputId": "cf945754-48c8-4aad-a64f-14c5068ab471"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: mobilenet_no_kd_new/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: mobilenet_no_kd_new/assets\n"
          ]
        }
      ],
      "source": [
        "#save student model with no kd\n",
        "mobilenet_no_kd.save('mobilenet_no_kd_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oSxptSzMy-1-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b21efd5-f559-420f-e424-8d9e4eca5547"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "#load student model with no kd\n",
        "mobilenet_no_kd=keras.models.load_model('/content/drive/MyDrive/mhist_dataset/mobilenet_no_kd_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVKoYWys93P0",
        "outputId": "80509458-5e88-4f35-9a9a-ef25ed117389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 66.84%\n",
            "Epoch 2: Class_accuracy: 71.24%\n",
            "Epoch 3: Class_accuracy: 63.36%\n",
            "Epoch 4: Class_accuracy: 76.05%\n",
            "Epoch 5: Class_accuracy: 70.83%\n",
            "Epoch 6: Class_accuracy: 79.94%\n",
            "Epoch 7: Class_accuracy: 78.51%\n",
            "Epoch 8: Class_accuracy: 77.18%\n",
            "Epoch 9: Class_accuracy: 76.05%\n",
            "Epoch 10: Class_accuracy: 76.66%\n",
            "fine tuning\n",
            "False input_5 1\n",
            "False Conv1 2\n",
            "False bn_Conv1 3\n",
            "False Conv1_re 4\n",
            "False expanded 5\n",
            "False expanded 6\n",
            "False expanded 7\n",
            "False expanded 8\n",
            "False expanded 9\n",
            "False block_1_ 10\n",
            "False block_1_ 11\n",
            "False block_1_ 12\n",
            "False block_1_ 13\n",
            "False block_1_ 14\n",
            "False block_1_ 15\n",
            "False block_1_ 16\n",
            "False block_1_ 17\n",
            "False block_1_ 18\n",
            "False block_2_ 19\n",
            "False block_2_ 20\n",
            "False block_2_ 21\n",
            "False block_2_ 22\n",
            "False block_2_ 23\n",
            "False block_2_ 24\n",
            "False block_2_ 25\n",
            "False block_2_ 26\n",
            "False block_2_ 27\n",
            "False block_3_ 28\n",
            "False block_3_ 29\n",
            "False block_3_ 30\n",
            "False block_3_ 31\n",
            "False block_3_ 32\n",
            "False block_3_ 33\n",
            "False block_3_ 34\n",
            "False block_3_ 35\n",
            "False block_3_ 36\n",
            "False block_4_ 37\n",
            "False block_4_ 38\n",
            "False block_4_ 39\n",
            "False block_4_ 40\n",
            "False block_4_ 41\n",
            "False block_4_ 42\n",
            "False block_4_ 43\n",
            "False block_4_ 44\n",
            "False block_4_ 45\n",
            "False block_5_ 46\n",
            "False block_5_ 47\n",
            "False block_5_ 48\n",
            "False block_5_ 49\n",
            "False block_5_ 50\n",
            "False block_5_ 51\n",
            "False block_5_ 52\n",
            "False block_5_ 53\n",
            "False block_5_ 54\n",
            "False block_6_ 55\n",
            "False block_6_ 56\n",
            "False block_6_ 57\n",
            "False block_6_ 58\n",
            "False block_6_ 59\n",
            "False block_6_ 60\n",
            "False block_6_ 61\n",
            "False block_6_ 62\n",
            "False block_6_ 63\n",
            "False block_7_ 64\n",
            "False block_7_ 65\n",
            "False block_7_ 66\n",
            "False block_7_ 67\n",
            "False block_7_ 68\n",
            "False block_7_ 69\n",
            "False block_7_ 70\n",
            "False block_7_ 71\n",
            "False block_7_ 72\n",
            "False block_8_ 73\n",
            "False block_8_ 74\n",
            "False block_8_ 75\n",
            "False block_8_ 76\n",
            "False block_8_ 77\n",
            "False block_8_ 78\n",
            "False block_8_ 79\n",
            "False block_8_ 80\n",
            "False block_8_ 81\n",
            "False block_9_ 82\n",
            "False block_9_ 83\n",
            "False block_9_ 84\n",
            "False block_9_ 85\n",
            "False block_9_ 86\n",
            "False block_9_ 87\n",
            "False block_9_ 88\n",
            "False block_9_ 89\n",
            "False block_9_ 90\n",
            "False block_10 91\n",
            "False block_10 92\n",
            "False block_10 93\n",
            "False block_10 94\n",
            "False block_10 95\n",
            "False block_10 96\n",
            "False block_10 97\n",
            "False block_10 98\n",
            "False block_11 99\n",
            "False block_11 100\n",
            "False block_11 101\n",
            "False block_11 102\n",
            "False block_11 103\n",
            "False block_11 104\n",
            "False block_11 105\n",
            "False block_11 106\n",
            "False block_11 107\n",
            "False block_12 108\n",
            "False block_12 109\n",
            "False block_12 110\n",
            "False block_12 111\n",
            "False block_12 112\n",
            "False block_12 113\n",
            "False block_12 114\n",
            "False block_12 115\n",
            "False block_12 116\n",
            "False block_13 117\n",
            "False block_13 118\n",
            "False block_13 119\n",
            "False block_13 120\n",
            "False block_13 121\n",
            "False block_13 122\n",
            "False block_13 123\n",
            "False block_13 124\n",
            "False block_13 125\n",
            "False block_14 126\n",
            "False block_14 127\n",
            "False block_14 128\n",
            "False block_14 129\n",
            "False block_14 130\n",
            "False block_14 131\n",
            "False block_14 132\n",
            "False block_14 133\n",
            "False block_14 134\n",
            "True block_15 135\n",
            "True block_15 136\n",
            "True block_15 137\n",
            "True block_15 138\n",
            "True block_15 139\n",
            "True block_15 140\n",
            "True block_15 141\n",
            "True block_15 142\n",
            "True block_15 143\n",
            "True block_16 144\n",
            "True block_16 145\n",
            "True block_16 146\n",
            "True block_16 147\n",
            "True block_16 148\n",
            "True block_16 149\n",
            "True block_16 150\n",
            "True block_16 151\n",
            "True Conv_1 152\n",
            "True Conv_1_b 153\n",
            "True out_relu 154\n",
            "True global_m 155\n",
            "Epoch 1: Class_accuracy: 74.72%\n",
            "Epoch 2: Class_accuracy: 79.63%\n",
            "Epoch 3: Class_accuracy: 77.58%\n",
            "Epoch 4: Class_accuracy: 77.89%\n",
            "Epoch 5: Class_accuracy: 81.58%\n",
            "Epoch 6: Class_accuracy: 79.32%\n",
            "Epoch 7: Class_accuracy: 77.69%\n",
            "Epoch 8: Class_accuracy: 76.97%\n",
            "Epoch 9: Class_accuracy: 72.47%\n",
            "Epoch 10: Class_accuracy: 73.39%\n",
            "Epoch 11: Class_accuracy: 70.52%\n",
            "Epoch 12: Class_accuracy: 75.03%\n",
            "Epoch 13: Class_accuracy: 80.04%\n",
            "Epoch 14: Class_accuracy: 79.94%\n",
            "Epoch 15: Class_accuracy: 80.66%\n",
            "Epoch 16: Class_accuracy: 81.37%\n",
            "Epoch 17: Class_accuracy: 79.53%\n",
            "Epoch 18: Class_accuracy: 81.78%\n",
            "Epoch 19: Class_accuracy: 81.78%\n",
            "Epoch 20: Class_accuracy: 81.27%\n",
            "Epoch 21: Class_accuracy: 78.10%\n",
            "Epoch 22: Class_accuracy: 76.36%\n",
            "Epoch 23: Class_accuracy: 78.51%\n",
            "Epoch 24: Class_accuracy: 75.64%\n",
            "Epoch 25: Class_accuracy: 79.43%\n"
          ]
        }
      ],
      "source": [
        "# training student with KD\n",
        "train_and_evaluate_kd(student_mobile, compute_student_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wdd5mQfjrBB8",
        "outputId": "db02d307-78ab-498d-a224-c4ff4c6a142a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: student_mobile/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: student_mobile/assets\n"
          ]
        }
      ],
      "source": [
        "# save student with KD\n",
        "student_mobile.save('student_mobile_new')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCXfYmfv4Dgu",
        "outputId": "8b736884-925c-4620-c41d-182f5bd69ac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "# load student with KD\n",
        "student_mobile=keras.models.load_model('/content/drive/MyDrive/mhist_dataset/student_mobile')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvgFnQclWIg3"
      },
      "source": [
        "#Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7h16HxfBWMKn"
      },
      "outputs": [],
      "source": [
        "#test labels for our test set\n",
        "test_label = test_generator.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUONVOFRaAJi"
      },
      "outputs": [],
      "source": [
        "# converting test labels to one hot encoded\n",
        "test_label_o = to_categorical(test_label, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yiZF7BPyaFuA",
        "outputId": "4cf3816c-d64e-4a19-8ba8-f88d86bfb746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 6s 140ms/step\n"
          ]
        }
      ],
      "source": [
        "#teacher prediction\n",
        "y_pred_o = teacher_res.predict(test_generator, verbose=1)\n",
        "y_pred = np.argmax(y_pred_o,axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QJLeNA0bkDx"
      },
      "outputs": [],
      "source": [
        "y_pred_onehot=to_categorical(y_pred, num_classes=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJs5la9Rauoo",
        "outputId": "a295ccd3-8184-4a13-f5f8-b8cfe5dc56ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 1 0 0 0 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 1 0 0 1\n",
            " 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 1 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 1 0 0\n",
            " 0 1 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
            " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
            " 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
            " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 1\n",
            " 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0\n",
            " 0 0 0 0 0 1 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 0 0 0 0 0 1 1 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 1 1 0 0 0 1 0 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 0 0 1 1 1 0 1 1\n",
            " 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 0 0 0 1 1 1 0 0 1 0 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 0 1 0 1 0 1 1 0 0 1 1 1 1 0 1 1 1 1 1 1 0 1\n",
            " 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
            " 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "print (y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHPZ2vF1ajWI",
        "outputId": "ebe46880-6d2f-40d7-ab21-79c5331fe0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating the teacher\n",
            "Precision:  0.84039086\n",
            "Recall:  0.71666664\n",
            "F1_score:  0.7736131521960075\n"
          ]
        }
      ],
      "source": [
        "# Precision, Recall, and F-1 score on the test set using teacher model\n",
        "\n",
        "precision_obj = tf.keras.metrics.Precision()\n",
        "precision_obj.update_state(test_label, y_pred)\n",
        "precision = precision_obj.result().numpy()\n",
        "\n",
        "\n",
        "recall_obj = tf.keras.metrics.Recall()\n",
        "recall_obj.update_state(test_label,  y_pred)\n",
        "recall = recall_obj.result().numpy()\n",
        "\n",
        "\n",
        "f1_score = 2*(precision*recall)/(recall+precision)\n",
        "print(\"Evaluating the teacher\")\n",
        "print('Precision: ',precision)\n",
        "print('Recall: ',recall)\n",
        "print('F1_score: ',f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTLr-0m43kZK",
        "outputId": "a8fa12f4-8ee6-43ae-a166-5a93f62f173e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 5s 132ms/step\n",
            "Evaluating the student with KD\n",
            "Precision:  0.8192771\n",
            "Recall:  0.56666666\n",
            "F1_score:  0.6699507463311767\n"
          ]
        }
      ],
      "source": [
        "# Precision, Recall, and F-1 score on the test set using student model with KD\n",
        "\n",
        "y_pred_o = student_mobile.predict(test_generator, verbose=1)\n",
        "y_pred = np.argmax(y_pred_o,axis=1)\n",
        "\n",
        "precision_obj = tf.keras.metrics.Precision()\n",
        "precision_obj.update_state(test_label, y_pred)\n",
        "precision = precision_obj.result().numpy()\n",
        "\n",
        "\n",
        "recall_obj = tf.keras.metrics.Recall()\n",
        "recall_obj.update_state(test_label,  y_pred)\n",
        "recall = recall_obj.result().numpy()\n",
        "\n",
        "\n",
        "f1_score = 2*(precision*recall)/(recall+precision)\n",
        "print(\"Evaluating the student with KD\")\n",
        "print('Precision: ',precision)\n",
        "print('Recall: ',recall)\n",
        "print('F1_score: ',f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXphA3ygWLLH",
        "outputId": "78fe1cfc-d605-450a-8448-cbbcbaefb604"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 5s 128ms/step\n",
            "Evaluating the student without KD\n",
            "Precision:  0.9411765\n",
            "Recall:  0.17777778\n",
            "F1_score:  0.2990654153334976\n"
          ]
        }
      ],
      "source": [
        "# Precision, Recall, and F-1 score on the test set using student model without KD\n",
        "\n",
        "y_pred_o = mobilenet_no_kd.predict(test_generator, verbose=1)\n",
        "y_pred = np.argmax(y_pred_o,axis=1)\n",
        "\n",
        "precision_obj = tf.keras.metrics.Precision()\n",
        "precision_obj.update_state(test_label, y_pred)\n",
        "precision = precision_obj.result().numpy()\n",
        "\n",
        "\n",
        "recall_obj = tf.keras.metrics.Recall()\n",
        "recall_obj.update_state(test_label,  y_pred)\n",
        "recall = recall_obj.result().numpy()\n",
        "\n",
        "\n",
        "f1_score = 2*(precision*recall)/(recall+precision)\n",
        "print(\"Evaluating the student without KD\")\n",
        "print('Precision: ',precision)\n",
        "print('Recall: ',recall)\n",
        "print('F1_score: ',f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision, Recall, and F-1 score on the test set using student model without KD\n",
        "\n",
        "y_pred_o = mobilenet_no_kd.predict(test_generator, verbose=1)\n",
        "y_pred = np.argmax(y_pred_o,axis=1)\n",
        "\n",
        "precision_obj = tf.keras.metrics.Precision()\n",
        "precision_obj.update_state(test_label, y_pred)\n",
        "precision = precision_obj.result().numpy()\n",
        "\n",
        "\n",
        "recall_obj = tf.keras.metrics.Recall()\n",
        "recall_obj.update_state(test_label,  y_pred)\n",
        "recall = recall_obj.result().numpy()\n",
        "\n",
        "\n",
        "f1_score = 2*(precision*recall)/(recall+precision)\n",
        "print(\"Evaluating the student without KD\")\n",
        "print('Precision: ',precision)\n",
        "print('Recall: ',recall)\n",
        "print('F1_score: ',f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2rkI78myFah",
        "outputId": "1f11254e-a76f-47fc-a6b1-fa18e0b75605"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31/31 [==============================] - 5s 149ms/step\n",
            "Evaluating the student without KD\n",
            "Precision:  0.9411765\n",
            "Recall:  0.17777778\n",
            "F1_score:  0.2990654153334976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYsfOXv2oHe6"
      },
      "source": [
        "#Graph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_kd_graph(model, compute_loss_fn, ALPHA=0.9, DISTILLATION_TEMPERATURE=8.):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "  for epoch in range(1, 10 + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels, ALPHA, DISTILLATION_TEMPERATURE)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(31):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "  \n",
        "  #fine tuning was removed due to compute time\n",
        " "
      ],
      "metadata": {
        "id": "tfictPJ0WTL-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6lhJf4Fl8Ga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8df296c-1d13-4e5d-9210-8448406d5281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "temp= 1\n",
            "Epoch 1: Class_accuracy: 63.15%\n",
            "Epoch 2: Class_accuracy: 63.15%\n",
            "Epoch 3: Class_accuracy: 63.46%\n",
            "Epoch 4: Class_accuracy: 67.96%\n",
            "Epoch 5: Class_accuracy: 69.29%\n",
            "Epoch 6: Class_accuracy: 77.18%\n",
            "Epoch 7: Class_accuracy: 75.23%\n",
            "Epoch 8: Class_accuracy: 77.38%\n",
            "Epoch 9: Class_accuracy: 80.45%\n",
            "Epoch 10: Class_accuracy: 77.99%\n",
            "31/31 [==============================] - 5s 128ms/step\n",
            "Evaluating the student with KD\n",
            "Precision:  0.6975477\n",
            "Recall:  0.7111111\n",
            "F1_score:  0.7042641227836637\n",
            "temp= 2\n",
            "Epoch 1: Class_accuracy: 63.15%\n",
            "Epoch 2: Class_accuracy: 63.15%\n",
            "Epoch 3: Class_accuracy: 63.15%\n",
            "Epoch 4: Class_accuracy: 63.87%\n",
            "Epoch 5: Class_accuracy: 63.46%\n",
            "Epoch 6: Class_accuracy: 73.69%\n",
            "Epoch 7: Class_accuracy: 70.62%\n",
            "Epoch 8: Class_accuracy: 70.83%\n",
            "Epoch 9: Class_accuracy: 77.79%\n",
            "Epoch 10: Class_accuracy: 79.94%\n",
            "31/31 [==============================] - 4s 123ms/step\n",
            "Evaluating the student with KD\n",
            "Precision:  0.7369942\n",
            "Recall:  0.7083333\n",
            "F1_score:  0.7223796106426391\n",
            "temp= 4\n",
            "Epoch 1: Class_accuracy: 63.15%\n",
            "Epoch 2: Class_accuracy: 63.15%\n",
            "Epoch 3: Class_accuracy: 63.15%\n",
            "Epoch 4: Class_accuracy: 63.15%\n",
            "Epoch 5: Class_accuracy: 63.15%\n",
            "Epoch 6: Class_accuracy: 65.30%\n",
            "Epoch 7: Class_accuracy: 63.36%\n",
            "Epoch 8: Class_accuracy: 68.68%\n",
            "Epoch 9: Class_accuracy: 70.73%\n",
            "Epoch 10: Class_accuracy: 69.81%\n",
            "31/31 [==============================] - 4s 122ms/step\n",
            "Evaluating the student with KD\n",
            "Precision:  0.85714287\n",
            "Recall:  0.21666667\n",
            "F1_score:  0.3458980177884264\n",
            "temp= 16\n",
            "Epoch 1: Class_accuracy: 67.14%\n",
            "Epoch 2: Class_accuracy: 69.50%\n",
            "Epoch 3: Class_accuracy: 67.55%\n",
            "Epoch 4: Class_accuracy: 61.11%\n",
            "Epoch 5: Class_accuracy: 76.36%\n",
            "Epoch 6: Class_accuracy: 78.10%\n",
            "Epoch 7: Class_accuracy: 79.32%\n",
            "Epoch 8: Class_accuracy: 80.04%\n",
            "Epoch 9: Class_accuracy: 80.55%\n",
            "Epoch 10: Class_accuracy: 64.07%\n",
            "31/31 [==============================] - 5s 122ms/step\n",
            "Evaluating the student with KD\n",
            "Precision:  0.5064935\n",
            "Recall:  0.975\n",
            "F1_score:  0.6666667068994763\n",
            "temp= 32\n",
            "Epoch 1: Class_accuracy: 69.91%\n",
            "Epoch 2: Class_accuracy: 66.94%\n",
            "Epoch 3: Class_accuracy: 74.31%\n",
            "Epoch 4: Class_accuracy: 67.25%\n",
            "Epoch 5: Class_accuracy: 68.68%\n",
            "Epoch 6: Class_accuracy: 66.12%\n",
            "Epoch 7: Class_accuracy: 74.10%\n",
            "Epoch 8: Class_accuracy: 78.51%\n",
            "Epoch 9: Class_accuracy: 75.84%\n",
            "Epoch 10: Class_accuracy: 73.69%\n",
            "31/31 [==============================] - 5s 124ms/step\n",
            "Evaluating the student with KD\n",
            "Precision:  0.80473375\n",
            "Recall:  0.37777779\n",
            "F1_score:  0.5141777018609371\n",
            "temp= 64\n",
            "Epoch 1: Class_accuracy: 63.56%\n",
            "Epoch 2: Class_accuracy: 63.15%\n",
            "Epoch 3: Class_accuracy: 64.18%\n",
            "Epoch 4: Class_accuracy: 64.38%\n",
            "Epoch 5: Class_accuracy: 74.00%\n",
            "Epoch 6: Class_accuracy: 76.15%\n",
            "Epoch 7: Class_accuracy: 81.37%\n",
            "Epoch 8: Class_accuracy: 80.14%\n",
            "Epoch 9: Class_accuracy: 76.25%\n",
            "Epoch 10: Class_accuracy: 79.63%\n",
            "31/31 [==============================] - 4s 118ms/step\n",
            "Evaluating the student with KD\n",
            "Precision:  0.7058824\n",
            "Recall:  0.76666665\n",
            "F1_score:  0.7350200394474508\n"
          ]
        }
      ],
      "source": [
        "temps=[1,2,4,16,32,64]\n",
        "ALPHA=0.5\n",
        "accuracy=[]\n",
        "for i in range(6):\n",
        "  print('temp=',temps[i])\n",
        "  mobilenet=tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    alpha=1.0,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling='max',\n",
        "  )\n",
        "  count=0\n",
        "  for layers in mobilenet.layers:\n",
        "    count+=1\n",
        "    if count> 151:\n",
        "      continue\n",
        "    if(layers.name[0:8]== 'block_16' ):\n",
        "      continue\n",
        "    else:\n",
        "      layers.trainable=False\n",
        "\n",
        "  student_mobile=tf.keras.Sequential([mobilenet,Dense(units=2, activation='linear')])\n",
        "\n",
        "  DISTILLATION_TEMPERATURE=temps[i]\n",
        "\n",
        "  train_and_evaluate_kd_graph(student_mobile, compute_student_loss, ALPHA,  DISTILLATION_TEMPERATURE)\n",
        "  y_pred_o = student_mobile.predict(test_generator, verbose=1)\n",
        "  y_pred = np.argmax(y_pred_o,axis=1)\n",
        "\n",
        "  precision_obj = tf.keras.metrics.Precision()\n",
        "  precision_obj.update_state(test_label, y_pred)\n",
        "  precision = precision_obj.result().numpy()\n",
        "\n",
        "\n",
        "  recall_obj = tf.keras.metrics.Recall()\n",
        "  recall_obj.update_state(test_label,  y_pred)\n",
        "  recall = recall_obj.result().numpy()\n",
        "\n",
        "\n",
        "  f1_score = 2*(precision*recall)/(recall+precision)\n",
        "  print(\"Evaluating the student with KD\")\n",
        "  print('Precision: ',precision)\n",
        "  print('Recall: ',recall)\n",
        "  print('F1_score: ',f1_score)\n",
        "  accuracy.append(f1_score)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting Test accuracy(F1 score) vs. tempreture curve\n",
        "plt.plot(temps, accuracy)\n",
        "plt.title('Test performance vs. tempreture curve')\n",
        "plt.xlabel('Temperture')\n",
        "plt.ylabel('F1 score')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xJkeX4-gm5zX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "1188826a-da12-47a8-9294-17019fc53962"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucjW0EtUyQ92"
      },
      "source": [
        "#Comparing the teacher and student model (number of of parameters and FLOPs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "INBsTZ2IyWZD"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.python.profiler.model_analyzer import profile\n",
        "from tensorflow.python.profiler.option_builder import ProfileOptionBuilder\n",
        "import numpy as np\n",
        "\n",
        "def get_flops(model):\n",
        " \n",
        "  forward_pass = tf.function(model.call,input_signature=[tf.TensorSpec(shape=(1,) + model.input_shape[1:])])\n",
        "  graph_info = profile(forward_pass.get_concrete_function().graph,\n",
        "                          options=ProfileOptionBuilder.float_operation())\n",
        "\n",
        "  # The //2 is important since `profile` counts multiply and accumulate as two flops\n",
        "  # We have calculated the total number of multiply accumulate ops\n",
        "  flops = graph_info.total_float_ops // 2\n",
        "  # Calculate no. of model parameters including trainable and non-trainable parameters\n",
        "  trainableParams = np.sum([np.prod(v.get_shape()) for v in model.trainable_weights])\n",
        "  nonTrainableParams = np.sum([np.prod(v.get_shape()) for v in model.non_trainable_weights])\n",
        "  totalParams = trainableParams + nonTrainableParams\n",
        "\n",
        "  return flops,trainableParams,nonTrainableParams,totalParams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHjLa0OUyXKx",
        "outputId": "6cfe8adc-27c5-4d52-8b33-95ceae24d8f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py:5219: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flops for teacher model: 3,484,727,297\n",
            "Total Parameters for teacher model: 23,568,898\n"
          ]
        }
      ],
      "source": [
        "#Calculating FLOPs and no. of parameters for the teacher model\n",
        "\n",
        "flops_teacher,teacher_trainableParams,teacher_nonTrainableParams,teacher_totalParams = get_flops(teacher_res)\n",
        "print('Flops for teacher model: {:,}'.format(flops_teacher))\n",
        "print('Total Parameters for teacher model: {:,}'.format(teacher_totalParams))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRj3HCS8yaSH",
        "outputId": "c060fcc2-f7eb-462c-9827-9098f9c65ba1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Flops for student model with KD: 299,496,833\n",
            "Total Parameters for student model with KD: 2,260,546\n"
          ]
        }
      ],
      "source": [
        "#Calculating FLOPs and no. of parameters for the student model\n",
        "\n",
        "flops_student,student_trainableParams,student_nonTrainableParams,student_totalParams = get_flops(student_mobile)\n",
        "print('Flops for student model with KD: {:,}'.format(flops_student))\n",
        "print('Total Parameters for student model with KD: {:,}'.format(student_totalParams))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSgPvajRgh7l"
      },
      "source": [
        "# Implementing the state-of-the-art KD algorithm using fitnets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Experimentation Dataset\n",
        "Again dataset was loaded as we faced some OOM issues with the previous batch size. Hence, Implemented fitnets with reduced batch size of the dataset."
      ],
      "metadata": {
        "id": "RWYj2s2oDQaC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGSAnTszDT0p"
      },
      "outputs": [],
      "source": [
        "image_table=pd.read_csv('/content/drive/My Drive/mhist_dataset/annotations.csv') #make sure you set the right path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3a829ca-bd23-4383-dc90-16f187c9223d",
        "id": "SO5n8xFSDT0r"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2175, 4)\n"
          ]
        }
      ],
      "source": [
        "train_set=image_table.loc[image_table['Partition'] == 'train']\n",
        "print(train_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e77452c9-9cd7-4bb9-ec81-b6360249cba3",
        "id": "d2xtZUa0DT0t"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(977, 4)\n"
          ]
        }
      ],
      "source": [
        "test_set=image_table.loc[image_table['Partition'] == 'test']\n",
        "print(test_set.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_zJ4gdxDT0u"
      },
      "outputs": [],
      "source": [
        "image_dir = '/content/drive/My Drive/mhist_dataset/images/images'  #you should change to your directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPtblBR_DT0v"
      },
      "outputs": [],
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1/255.,\n",
        "shear_range=0.1,\n",
        "rotation_range=15,\n",
        "horizontal_flip=True,\n",
        "vertical_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1/255.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7770fe2-04b7-47f4-8be5-20078a195348",
        "id": "zPfsu3BxDT0w"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2175 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_generator=train_datagen.flow_from_dataframe(\n",
        "dataframe=train_set,\n",
        "directory=image_dir,\n",
        "x_col=\"Image Name\",\n",
        "y_col=\"Majority Vote Label\",\n",
        "batch_size=24,\n",
        "seed=42,\n",
        "shuffle=True,\n",
        "interpolation='bilinear',\n",
        "class_mode=\"categorical\",\n",
        "target_size=(224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96e13516-0278-46cd-cd83-7671fdc58fd7",
        "id": "EYArYtolDT0y"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 977 validated image filenames belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_generator=test_datagen.flow_from_dataframe(\n",
        "dataframe=test_set,\n",
        "directory=image_dir,\n",
        "x_col=\"Image Name\",\n",
        "y_col=\"Majority Vote Label\",\n",
        "seed=42,\n",
        "class_mode='categorical',\n",
        "interpolation='bilinear',\n",
        "target_size=(224, 224),\n",
        "batch_size=24,\n",
        "shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fitnets KD Implementation with Transfer Learning"
      ],
      "metadata": {
        "id": "jY30ZBXRDWzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model Creation with Fitnets setup"
      ],
      "metadata": {
        "id": "OH6FkIwLi5co"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-BdjrJY9q8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da2af7ad-55ee-4136-bf19-2a48ab08adac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94668760/94668760 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet_fitnets=tf.keras.applications.ResNet50V2(\n",
        "    include_top=False,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    pooling='avg',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e2f487-8196-4eee-df23-b0e63bb111af",
        "id": "fg2MTcMy9q8x"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "191\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for layers in resnet_fitnets.layers:\n",
        "  count+=1\n",
        "  if count== 191:\n",
        "    continue\n",
        "  if(layers.name[0:5]== 'conv5' or layers.name[0:5]== 'post_'):\n",
        "    continue\n",
        "  else:\n",
        "    layers.trainable=False\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XjYAhHpz-D_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90550247-8f31-4a07-ab71-a51ec102194c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9406464/9406464 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "mobilenet_fitnets=tf.keras.applications.MobileNetV2(\n",
        "    include_top=False,\n",
        "    input_shape=(224, 224, 3),\n",
        "    alpha=1.0,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    pooling='max',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f54313c-48f0-4a7a-8466-aa4546c39e46",
        "id": "UtaZg9iD-D_7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155\n"
          ]
        }
      ],
      "source": [
        "count=0\n",
        "for layers in mobilenet_fitnets.layers:\n",
        "  count+=1\n",
        "  if count> 151:\n",
        "    continue\n",
        "  if(layers.name[0:8]== 'block_16' ):\n",
        "    continue\n",
        "  else:\n",
        "    layers.trainable=False\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-iGoDbv7gj9h"
      },
      "outputs": [],
      "source": [
        "#Model Creation for student baby till the guided layer\n",
        "student_baby =  tf.keras.Sequential([mobilenet_fitnets,Dense(units=2048, activation='linear')])\n",
        "\n",
        "#Model Creation for student test incorporating student baby and the rest of the layers\n",
        "student_test=tf.keras.Sequential([student_baby,Dense(units=2, activation='linear')])\n",
        "\n",
        "#Model Creation for teacher baby till the hint layer\n",
        "teacher_baby =  tf.keras.Sequential([resnet_fitnets])\n",
        "\n",
        "#Model Creation for teacher test incorporating student baby and the rest of the layers\n",
        "teacher_test =  teacher_res=tf.keras.Sequential([teacher_baby,Dense(units=2, activation='linear')])                                                                "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_baby.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WUSt-TRKVgz",
        "outputId": "e751b48e-036b-4551-f7f5-a006dca5a3bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50v2 (Functional)     (None, 2048)              23564800  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,564,800\n",
            "Trainable params: 14,970,880\n",
            "Non-trainable params: 8,593,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#teacher_test.build(input_shape=(None,224,224,3))\n",
        "teacher_test.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P0QgvNBJBQp",
        "outputId": "6dec1190-fed2-4ad0-9655-a3f500aa7f81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_2 (Sequential)   (None, 2048)              23564800  \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,568,898\n",
            "Trainable params: 14,974,978\n",
            "Non-trainable params: 8,593,920\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_teacher_loss_fit(images, labels):\n",
        "  \"\"\"Compute subclass knowledge distillation teacher loss with Fitnets setup for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  subclass_logits = teacher_test(images, training=True)\n",
        "\n",
        "  # Compute cross-entropy loss for subclasses.\n",
        " \n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(axis=-1,name='categorical_crossentropy')\n",
        "  cross_entropy_loss_value = loss(labels,tf.nn.softmax(subclass_logits, axis=-1))\n",
        "\n",
        "  return cross_entropy_loss_value"
      ],
      "metadata": {
        "id": "vZJGsDinJKJc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_teacher_fitnets(model, compute_loss_fn):\n",
        "  \"\"\"Perform training and evaluation for a given model.\n",
        "\n",
        "  Args:\n",
        "    model: Instance of tf.keras.Model.\n",
        "    compute_loss_fn: A function that computes the training loss given the\n",
        "      images, and labels.\n",
        "  \"\"\"\n",
        "\n",
        "  # your code start from here for step 4\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  for epoch in range(1, 10 + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "        \n",
        "        # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(41):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "    \n",
        "  #fine tuning\n",
        "  print('fine tuning')\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.00001)\n",
        "\n",
        "  m=teacher_test.get_layer('sequential_2')\n",
        "  m=m.get_layer('resnet50v2')\n",
        "  count=0\n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    if count== 152:\n",
        "      layers.trainable=True\n",
        "    if(layers.name[0:5]== 'conv4'):\n",
        "      layers.trainable=True\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  count=0  \n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    print(layers.trainable, layers.name[0:5], count)\n",
        "\n",
        "  for epoch in range(1, 25 + 1):\n",
        "  # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(68):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "        # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images,labels)\n",
        "\n",
        "      grads = tape.gradient(loss_value, model.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    \n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(41):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(model,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))"
      ],
      "metadata": {
        "id": "OPc31de_I2lG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_evaluate_teacher_fitnets(teacher_test,compute_teacher_loss_fit)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgCY1w_NJQPk",
        "outputId": "8e7219ce-4e3d-40da-b98c-4915cde75b34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 82.70%\n",
            "Epoch 2: Class_accuracy: 79.12%\n",
            "Epoch 3: Class_accuracy: 82.50%\n",
            "Epoch 4: Class_accuracy: 79.73%\n",
            "Epoch 5: Class_accuracy: 82.80%\n",
            "Epoch 6: Class_accuracy: 82.19%\n",
            "Epoch 7: Class_accuracy: 84.34%\n",
            "Epoch 8: Class_accuracy: 82.80%\n",
            "Epoch 9: Class_accuracy: 86.08%\n",
            "Epoch 10: Class_accuracy: 81.27%\n",
            "fine tuning\n",
            "False input 1\n",
            "False conv1 2\n",
            "False conv1 3\n",
            "False pool1 4\n",
            "False pool1 5\n",
            "False conv2 6\n",
            "False conv2 7\n",
            "False conv2 8\n",
            "False conv2 9\n",
            "False conv2 10\n",
            "False conv2 11\n",
            "False conv2 12\n",
            "False conv2 13\n",
            "False conv2 14\n",
            "False conv2 15\n",
            "False conv2 16\n",
            "False conv2 17\n",
            "False conv2 18\n",
            "False conv2 19\n",
            "False conv2 20\n",
            "False conv2 21\n",
            "False conv2 22\n",
            "False conv2 23\n",
            "False conv2 24\n",
            "False conv2 25\n",
            "False conv2 26\n",
            "False conv2 27\n",
            "False conv2 28\n",
            "False conv2 29\n",
            "False conv2 30\n",
            "False conv2 31\n",
            "False conv2 32\n",
            "False conv2 33\n",
            "False conv2 34\n",
            "False conv2 35\n",
            "False conv2 36\n",
            "False conv2 37\n",
            "False max_p 38\n",
            "False conv2 39\n",
            "False conv2 40\n",
            "False conv3 41\n",
            "False conv3 42\n",
            "False conv3 43\n",
            "False conv3 44\n",
            "False conv3 45\n",
            "False conv3 46\n",
            "False conv3 47\n",
            "False conv3 48\n",
            "False conv3 49\n",
            "False conv3 50\n",
            "False conv3 51\n",
            "False conv3 52\n",
            "False conv3 53\n",
            "False conv3 54\n",
            "False conv3 55\n",
            "False conv3 56\n",
            "False conv3 57\n",
            "False conv3 58\n",
            "False conv3 59\n",
            "False conv3 60\n",
            "False conv3 61\n",
            "False conv3 62\n",
            "False conv3 63\n",
            "False conv3 64\n",
            "False conv3 65\n",
            "False conv3 66\n",
            "False conv3 67\n",
            "False conv3 68\n",
            "False conv3 69\n",
            "False conv3 70\n",
            "False conv3 71\n",
            "False conv3 72\n",
            "False conv3 73\n",
            "False conv3 74\n",
            "False conv3 75\n",
            "False conv3 76\n",
            "False conv3 77\n",
            "False conv3 78\n",
            "False conv3 79\n",
            "False conv3 80\n",
            "False conv3 81\n",
            "False conv3 82\n",
            "False conv3 83\n",
            "False max_p 84\n",
            "False conv3 85\n",
            "False conv3 86\n",
            "True conv4 87\n",
            "True conv4 88\n",
            "True conv4 89\n",
            "True conv4 90\n",
            "True conv4 91\n",
            "True conv4 92\n",
            "True conv4 93\n",
            "True conv4 94\n",
            "True conv4 95\n",
            "True conv4 96\n",
            "True conv4 97\n",
            "True conv4 98\n",
            "True conv4 99\n",
            "True conv4 100\n",
            "True conv4 101\n",
            "True conv4 102\n",
            "True conv4 103\n",
            "True conv4 104\n",
            "True conv4 105\n",
            "True conv4 106\n",
            "True conv4 107\n",
            "True conv4 108\n",
            "True conv4 109\n",
            "True conv4 110\n",
            "True conv4 111\n",
            "True conv4 112\n",
            "True conv4 113\n",
            "True conv4 114\n",
            "True conv4 115\n",
            "True conv4 116\n",
            "True conv4 117\n",
            "True conv4 118\n",
            "True conv4 119\n",
            "True conv4 120\n",
            "True conv4 121\n",
            "True conv4 122\n",
            "True conv4 123\n",
            "True conv4 124\n",
            "True conv4 125\n",
            "True conv4 126\n",
            "True conv4 127\n",
            "True conv4 128\n",
            "True conv4 129\n",
            "True conv4 130\n",
            "True conv4 131\n",
            "True conv4 132\n",
            "True conv4 133\n",
            "True conv4 134\n",
            "True conv4 135\n",
            "True conv4 136\n",
            "True conv4 137\n",
            "True conv4 138\n",
            "True conv4 139\n",
            "True conv4 140\n",
            "True conv4 141\n",
            "True conv4 142\n",
            "True conv4 143\n",
            "True conv4 144\n",
            "True conv4 145\n",
            "True conv4 146\n",
            "True conv4 147\n",
            "True conv4 148\n",
            "True conv4 149\n",
            "True conv4 150\n",
            "True conv4 151\n",
            "True max_p 152\n",
            "True conv4 153\n",
            "True conv4 154\n",
            "True conv5 155\n",
            "True conv5 156\n",
            "True conv5 157\n",
            "True conv5 158\n",
            "True conv5 159\n",
            "True conv5 160\n",
            "True conv5 161\n",
            "True conv5 162\n",
            "True conv5 163\n",
            "True conv5 164\n",
            "True conv5 165\n",
            "True conv5 166\n",
            "True conv5 167\n",
            "True conv5 168\n",
            "True conv5 169\n",
            "True conv5 170\n",
            "True conv5 171\n",
            "True conv5 172\n",
            "True conv5 173\n",
            "True conv5 174\n",
            "True conv5 175\n",
            "True conv5 176\n",
            "True conv5 177\n",
            "True conv5 178\n",
            "True conv5 179\n",
            "True conv5 180\n",
            "True conv5 181\n",
            "True conv5 182\n",
            "True conv5 183\n",
            "True conv5 184\n",
            "True conv5 185\n",
            "True conv5 186\n",
            "True conv5 187\n",
            "True conv5 188\n",
            "True post_ 189\n",
            "True post_ 190\n",
            "True avg_p 191\n",
            "Epoch 1: Class_accuracy: 83.01%\n",
            "Epoch 2: Class_accuracy: 84.14%\n",
            "Epoch 3: Class_accuracy: 84.65%\n",
            "Epoch 4: Class_accuracy: 84.34%\n",
            "Epoch 5: Class_accuracy: 85.16%\n",
            "Epoch 6: Class_accuracy: 85.36%\n",
            "Epoch 7: Class_accuracy: 85.16%\n",
            "Epoch 8: Class_accuracy: 85.98%\n",
            "Epoch 9: Class_accuracy: 85.98%\n",
            "Epoch 10: Class_accuracy: 85.88%\n",
            "Epoch 11: Class_accuracy: 86.90%\n",
            "Epoch 12: Class_accuracy: 86.39%\n",
            "Epoch 13: Class_accuracy: 85.57%\n",
            "Epoch 14: Class_accuracy: 85.67%\n",
            "Epoch 15: Class_accuracy: 87.10%\n",
            "Epoch 16: Class_accuracy: 86.90%\n",
            "Epoch 17: Class_accuracy: 86.18%\n",
            "Epoch 18: Class_accuracy: 86.49%\n",
            "Epoch 19: Class_accuracy: 86.69%\n",
            "Epoch 20: Class_accuracy: 87.10%\n",
            "Epoch 21: Class_accuracy: 85.57%\n",
            "Epoch 22: Class_accuracy: 86.59%\n",
            "Epoch 23: Class_accuracy: 86.39%\n",
            "Epoch 24: Class_accuracy: 86.28%\n",
            "Epoch 25: Class_accuracy: 85.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_test.save('teacher_test')"
      ],
      "metadata": {
        "id": "xnQqy42oVOsP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_test=keras.models.load_model('/content/drive/MyDrive/mhist_dataset/teacher_test')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPRyTng3iYIh",
        "outputId": "afd32520-243c-46b6-8f09-dd04f413a2dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision, Recall, and F-1 score on the test set using teacher fitnet\n",
        "\n",
        "y_pred_o = teacher_test.predict(test_generator, verbose=1)\n",
        "y_pred = np.argmax(y_pred_o,axis=1)\n",
        "\n",
        "precision_obj = tf.keras.metrics.Precision()\n",
        "precision_obj.update_state(test_label, y_pred)\n",
        "precision = precision_obj.result().numpy()\n",
        "\n",
        "\n",
        "recall_obj = tf.keras.metrics.Recall()\n",
        "recall_obj.update_state(test_label,  y_pred)\n",
        "recall = recall_obj.result().numpy()\n",
        "\n",
        "\n",
        "f1_score = 2*(precision*recall)/(recall+precision)\n",
        "print(\"Evaluating the Teacher for fitnet\")\n",
        "print('Precision: ',precision)\n",
        "print('Recall: ',recall)\n",
        "print('F1_score: ',f1_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjNZOzTuCFlU",
        "outputId": "3a740afa-68e3-4544-e416-854ddf7d2688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 4s 93ms/step\n",
            "Evaluating the Teacher for fitnet\n",
            "Precision:  0.8646865\n",
            "Recall:  0.7277778\n",
            "F1_score:  0.7903469820619861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqF5PxO_j1aF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "602988c8-a71e-466c-81f7-dfb322d70750"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential (Sequential)     (None, 2048)              4881472   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,885,570\n",
            "Trainable params: 3,513,666\n",
            "Non-trainable params: 1,371,904\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "student_test.build(input_shape=(None,224,224,3))\n",
        "student_test.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "student_baby.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkEZp1V-Cf-Z",
        "outputId": "6642bfea-c457-4866-9786-aba6aa662adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 1280)             2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              2623488   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,881,472\n",
            "Trainable params: 3,509,568\n",
            "Non-trainable params: 1,371,904\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wsbFuu59j4pg"
      },
      "outputs": [],
      "source": [
        "def compute_student_loss(images, labels,teacher_baby, student_baby, ALPHA=0.9):\n",
        "  \"\"\"Compute subclass knowledge distillation student loss with fitnets setup for given images\n",
        "     and labels.\n",
        "\n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    labels: Tensor representing a batch of labels.\n",
        "    teacher_baby: The TensorFlow teacher model with final layer as hint layer \n",
        "    student_baby: The TensorFlow student model with final layer as guided layer\n",
        "    ALPHA: weight parameter to balance the contribution of two losses\n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  student_subclass_logits = student_test(images, training=True)\n",
        "\n",
        "  # Compute subclass distillation loss between student subclass logits and\n",
        "  # softened teacher subclass targets probabilities.\n",
        "\n",
        "  teacher_subclass_logits = teacher_test(images, training=False)\n",
        "  distillation_loss_value = compute_student_loss_new(teacher_baby, student_baby, images)\n",
        "\n",
        "  # Compute cross-entropy loss with hard targets.\n",
        "\n",
        "  loss=tf.keras.losses.CategoricalCrossentropy(axis=-1,name='categorical_crossentropy')\n",
        "  cross_entropy_loss_value = loss(labels,tf.nn.softmax(student_subclass_logits, axis=-1))\n",
        "\n",
        "  return (ALPHA*  distillation_loss_value + (1-ALPHA)* cross_entropy_loss_value) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uySgsAQPj8Mq"
      },
      "outputs": [],
      "source": [
        "def compute_student_loss_new(teacher_baby, student_baby, inp_imag):\n",
        "  \"\"\"\n",
        "  Compute L2 norm of the outputs of these hint and guided layers \n",
        "  Args:\n",
        "    images: Tensor representing a batch of images.\n",
        "    teacher_baby: The TensorFlow teacher model with final layer as hint layer \n",
        "    student_baby: The TensorFlow student model with final layer as guided layer\n",
        "    \n",
        "  Returns:\n",
        "    Scalar loss Tensor.\n",
        "  \"\"\"\n",
        "  prediction_student_baby = student_baby(inp_imag)\n",
        "  prediction_teacher_baby = teacher_baby(inp_imag)\n",
        "  loss = tf.math.sqrt(tf.math.reduce_sum(tf.math.pow((prediction_teacher_baby-prediction_student_baby),2)))\n",
        "  return loss "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate_fitnets(student_test,teacher_baby,student_baby, compute_loss_fn):\n",
        "  \"\"\"\n",
        "  Compute subclass knowledge distillation student test loss using fitnets method for the given images\n",
        "     and labels. Fitnets loss is calculated as the weighted sum of the L2 norm of the outputs of these hint \n",
        "     and guided layers along with the hard labels cross entropy loss for the student. \n",
        "\n",
        "  Args:\n",
        "\n",
        "    teacher_baby: The TensorFlow teacher model with final layer as hint layer \n",
        "    student_baby: The TensorFlow student model with final layer as guided layer\n",
        "    student: The Tensorflow student model consisting of baby student followed by the classification layer \n",
        "    teacher: The TensorFlow teacher model consisting of baby teacher followed by the dropout and the classification layer\n",
        "    compute_loss_fn: loss function for fitnets\n",
        "  Returns:\n",
        "    Prints the Epoch wise model accuracy.\n",
        "  \"\"\"\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  for epoch in range(1, 10 + 1):\n",
        "    # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(91):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "         loss_value = compute_loss_fn(images, labels,teacher_baby, student_baby,ALPHA=0.8)\n",
        "      grads = tape.gradient(loss_value, student_test.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, student_test.trainable_variables))\n",
        "\n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(41):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(student_test,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))\n",
        "  \n",
        "  #fine tuning\n",
        "  print('fine tuning')\n",
        "  optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "\n",
        "  m=student_test.get_layer('sequential')\n",
        "  m=m.get_layer('mobilenetv2_1.00_224')\n",
        "\n",
        "  for layers in m.layers:\n",
        "    if(layers.name[0:8]== 'block_15'):\n",
        "      layers.trainable=True\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  count=0  \n",
        "  for layers in m.layers:\n",
        "    count+=1\n",
        "    print(layers.trainable, layers.name[0:8], count)\n",
        "\n",
        "  for epoch in range(1, 25 + 1):\n",
        "  # Run training.\n",
        "    print('Epoch {}: '.format(epoch), end='')\n",
        "    train_generator.reset()\n",
        "    for _ in range(91):\n",
        "      images, labels=train_generator.next()\n",
        "      with tf.GradientTape() as tape:\n",
        "        # your code start from here for step 4\n",
        "\n",
        "        loss_value = compute_loss_fn(images, labels,teacher_baby, student_baby,ALPHA=0.8)\n",
        "\n",
        "      grads = tape.gradient(loss_value, student_test.trainable_variables)\n",
        "      optimizer.apply_gradients(zip(grads, student_test.trainable_variables))\n",
        "    \n",
        "    # Run evaluation.\n",
        "    num_correct = 0\n",
        "    num_total = 0\n",
        "    for _ in range(41):\n",
        "      # your code start from here for step 4\n",
        "      images, labels=test_generator.next()\n",
        "      num_total+= len(labels)\n",
        "      num_correct += compute_num_correct(student_test,images,labels)[0] \n",
        "    print(\"Class_accuracy: \" + '{:.2f}%'.format(\n",
        "        num_correct / num_total * 100))"
      ],
      "metadata": {
        "id": "_hFf7opIkD3V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPPX-FFwkGFF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "880df4ce-0bfa-4253-fdf4-d1df69c0bfd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: Class_accuracy: 71.75%\n",
            "Epoch 2: Class_accuracy: 73.29%\n",
            "Epoch 3: Class_accuracy: 72.47%\n",
            "Epoch 4: Class_accuracy: 74.62%\n",
            "Epoch 5: Class_accuracy: 63.66%\n",
            "Epoch 6: Class_accuracy: 63.46%\n",
            "Epoch 7: Class_accuracy: 63.87%\n",
            "Epoch 8: Class_accuracy: 63.56%\n",
            "Epoch 9: Class_accuracy: 63.15%\n",
            "Epoch 10: Class_accuracy: 65.51%\n",
            "fine tuning\n",
            "False input_2 1\n",
            "False Conv1 2\n",
            "False bn_Conv1 3\n",
            "False Conv1_re 4\n",
            "False expanded 5\n",
            "False expanded 6\n",
            "False expanded 7\n",
            "False expanded 8\n",
            "False expanded 9\n",
            "False block_1_ 10\n",
            "False block_1_ 11\n",
            "False block_1_ 12\n",
            "False block_1_ 13\n",
            "False block_1_ 14\n",
            "False block_1_ 15\n",
            "False block_1_ 16\n",
            "False block_1_ 17\n",
            "False block_1_ 18\n",
            "False block_2_ 19\n",
            "False block_2_ 20\n",
            "False block_2_ 21\n",
            "False block_2_ 22\n",
            "False block_2_ 23\n",
            "False block_2_ 24\n",
            "False block_2_ 25\n",
            "False block_2_ 26\n",
            "False block_2_ 27\n",
            "False block_3_ 28\n",
            "False block_3_ 29\n",
            "False block_3_ 30\n",
            "False block_3_ 31\n",
            "False block_3_ 32\n",
            "False block_3_ 33\n",
            "False block_3_ 34\n",
            "False block_3_ 35\n",
            "False block_3_ 36\n",
            "False block_4_ 37\n",
            "False block_4_ 38\n",
            "False block_4_ 39\n",
            "False block_4_ 40\n",
            "False block_4_ 41\n",
            "False block_4_ 42\n",
            "False block_4_ 43\n",
            "False block_4_ 44\n",
            "False block_4_ 45\n",
            "False block_5_ 46\n",
            "False block_5_ 47\n",
            "False block_5_ 48\n",
            "False block_5_ 49\n",
            "False block_5_ 50\n",
            "False block_5_ 51\n",
            "False block_5_ 52\n",
            "False block_5_ 53\n",
            "False block_5_ 54\n",
            "False block_6_ 55\n",
            "False block_6_ 56\n",
            "False block_6_ 57\n",
            "False block_6_ 58\n",
            "False block_6_ 59\n",
            "False block_6_ 60\n",
            "False block_6_ 61\n",
            "False block_6_ 62\n",
            "False block_6_ 63\n",
            "False block_7_ 64\n",
            "False block_7_ 65\n",
            "False block_7_ 66\n",
            "False block_7_ 67\n",
            "False block_7_ 68\n",
            "False block_7_ 69\n",
            "False block_7_ 70\n",
            "False block_7_ 71\n",
            "False block_7_ 72\n",
            "False block_8_ 73\n",
            "False block_8_ 74\n",
            "False block_8_ 75\n",
            "False block_8_ 76\n",
            "False block_8_ 77\n",
            "False block_8_ 78\n",
            "False block_8_ 79\n",
            "False block_8_ 80\n",
            "False block_8_ 81\n",
            "False block_9_ 82\n",
            "False block_9_ 83\n",
            "False block_9_ 84\n",
            "False block_9_ 85\n",
            "False block_9_ 86\n",
            "False block_9_ 87\n",
            "False block_9_ 88\n",
            "False block_9_ 89\n",
            "False block_9_ 90\n",
            "False block_10 91\n",
            "False block_10 92\n",
            "False block_10 93\n",
            "False block_10 94\n",
            "False block_10 95\n",
            "False block_10 96\n",
            "False block_10 97\n",
            "False block_10 98\n",
            "False block_11 99\n",
            "False block_11 100\n",
            "False block_11 101\n",
            "False block_11 102\n",
            "False block_11 103\n",
            "False block_11 104\n",
            "False block_11 105\n",
            "False block_11 106\n",
            "False block_11 107\n",
            "False block_12 108\n",
            "False block_12 109\n",
            "False block_12 110\n",
            "False block_12 111\n",
            "False block_12 112\n",
            "False block_12 113\n",
            "False block_12 114\n",
            "False block_12 115\n",
            "False block_12 116\n",
            "False block_13 117\n",
            "False block_13 118\n",
            "False block_13 119\n",
            "False block_13 120\n",
            "False block_13 121\n",
            "False block_13 122\n",
            "False block_13 123\n",
            "False block_13 124\n",
            "False block_13 125\n",
            "False block_14 126\n",
            "False block_14 127\n",
            "False block_14 128\n",
            "False block_14 129\n",
            "False block_14 130\n",
            "False block_14 131\n",
            "False block_14 132\n",
            "False block_14 133\n",
            "False block_14 134\n",
            "True block_15 135\n",
            "True block_15 136\n",
            "True block_15 137\n",
            "True block_15 138\n",
            "True block_15 139\n",
            "True block_15 140\n",
            "True block_15 141\n",
            "True block_15 142\n",
            "True block_15 143\n",
            "True block_16 144\n",
            "True block_16 145\n",
            "True block_16 146\n",
            "True block_16 147\n",
            "True block_16 148\n",
            "True block_16 149\n",
            "True block_16 150\n",
            "True block_16 151\n",
            "True Conv_1 152\n",
            "True Conv_1_b 153\n",
            "True out_relu 154\n",
            "True global_m 155\n",
            "Epoch 1: Class_accuracy: 74.92%\n",
            "Epoch 2: Class_accuracy: 63.36%\n",
            "Epoch 3: Class_accuracy: 71.44%\n",
            "Epoch 4: Class_accuracy: 73.29%\n",
            "Epoch 5: Class_accuracy: 75.33%\n",
            "Epoch 6: Class_accuracy: 74.92%\n",
            "Epoch 7: Class_accuracy: 74.92%\n",
            "Epoch 8: Class_accuracy: 76.87%\n",
            "Epoch 9: Class_accuracy: 72.88%\n",
            "Epoch 10: Class_accuracy: 75.64%\n",
            "Epoch 11: Class_accuracy: 74.82%\n",
            "Epoch 12: Class_accuracy: 79.22%\n",
            "Epoch 13: Class_accuracy: 79.73%\n",
            "Epoch 14: Class_accuracy: 77.79%\n",
            "Epoch 15: Class_accuracy: 76.15%\n",
            "Epoch 16: Class_accuracy: 77.79%\n",
            "Epoch 17: Class_accuracy: 77.69%\n",
            "Epoch 18: Class_accuracy: 77.69%\n",
            "Epoch 19: Class_accuracy: 72.88%\n",
            "Epoch 20: Class_accuracy: 80.04%\n",
            "Epoch 21: Class_accuracy: 74.00%\n",
            "Epoch 22: Class_accuracy: 79.32%\n",
            "Epoch 23: Class_accuracy: 76.66%\n",
            "Epoch 24: Class_accuracy: 79.63%\n",
            "Epoch 25: Class_accuracy: 74.41%\n"
          ]
        }
      ],
      "source": [
        "#Calculating student loss with the Fitnets setup\n",
        "train_and_evaluate_fitnets(student_test,teacher_baby,student_baby, compute_student_loss)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision, Recall, and F-1 score on the test set using student fitnet model with KD\n",
        "\n",
        "y_pred_o = student_test.predict(test_generator, verbose=1)\n",
        "y_pred = np.argmax(y_pred_o,axis=1)\n",
        "\n",
        "precision_obj = tf.keras.metrics.Precision()\n",
        "precision_obj.update_state(test_label, y_pred)\n",
        "precision = precision_obj.result().numpy()\n",
        "\n",
        "\n",
        "recall_obj = tf.keras.metrics.Recall()\n",
        "recall_obj.update_state(test_label,  y_pred)\n",
        "recall = recall_obj.result().numpy()\n",
        "\n",
        "\n",
        "f1_score = 2*(precision*recall)/(recall+precision)\n",
        "print(\"Evaluating the student fitnet\")\n",
        "print('Precision: ',precision)\n",
        "print('Recall: ',recall)\n",
        "print('F1_score: ',f1_score)"
      ],
      "metadata": {
        "id": "a5gLdzrQo8Js",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69d11dc9-f8ac-49b1-e392-19ffd0d0f0fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 8s 158ms/step\n",
            "Evaluating the student fitnet\n",
            "Precision:  0.9230769\n",
            "Recall:  0.33333334\n",
            "F1_score:  0.48979594257164905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_Tge2stveV6b"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}